{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data options\n",
    "\n",
    "RESOLUTION = (600, 600)\n",
    "FRAME_RATE = 30\n",
    "\n",
    "INPUT_PATH=\"./input/\"\n",
    "OUTPUT_PATH=\"./\"\n",
    "\n",
    "MODEL_FILE = \"pose_landmarker_full.task\"\n",
    "MP_DATA_FILE = \"mp_data.pkl\"\n",
    "VIDEO_FILE = \"output.mp4\"\n",
    "\n",
    "# model options\n",
    "TRESHOLD = 0.05\n",
    "CUTOFF = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mediapipe options\n",
    "\n",
    "# LANDMARK_POINTS = np.int32(33)\n",
    "LANDMARK_POINTS = np.int32(11) # other pose points are removed, we focus on the face only (including other points may cause increased detection of movement)\n",
    "LANDMARK_DIM = np.int32(3)\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "model_path = os.path.join(os.path.abspath(OUTPUT_PATH), MODEL_FILE)\n",
    "\n",
    "MP_OPTIONS = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    num_poses=1,\n",
    "    min_pose_detection_confidence=0.65, # The minimum confidence score for the pose detection to be considered successful.\n",
    "    min_pose_presence_confidence=0.75, # The minimum confidence score of pose presence score in the pose landmark detection.\n",
    "    min_tracking_confidence=0.45, # The minimum confidence score for the pose tracking to be considered successful.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/kappa/dev/computer-vision/proj/input/frame_0001.jpg',\n",
       "       '/home/kappa/dev/computer-vision/proj/input/frame_0002.jpg',\n",
       "       '/home/kappa/dev/computer-vision/proj/input/frame_0003.jpg',\n",
       "       '/home/kappa/dev/computer-vision/proj/input/frame_0004.jpg',\n",
       "       '/home/kappa/dev/computer-vision/proj/input/frame_0005.jpg'],\n",
       "      dtype='<U58')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = os.path.abspath(INPUT_PATH)\n",
    "\n",
    "image_files = sorted(os.listdir(input_path))\n",
    "image_files = np.array(list(map(lambda x: os.path.join(input_path, x), filter(lambda x: x.endswith(\".jpg\"), image_files))))\n",
    "image_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_images(files):\n",
    "\n",
    "    with PoseLandmarker.create_from_options(MP_OPTIONS) as landmarker:\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for i, file in enumerate(files):\n",
    "            mp_image = mp.Image.create_from_file(file)\n",
    "\n",
    "            result = landmarker.detect(mp_image)\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Processed {i} images\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.path.abspath(OUTPUT_PATH), MP_DATA_FILE)\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"rb\") as f:\n",
    "        mp_data = pkl.load(f)\n",
    "\n",
    "else:\n",
    "    mp_data = parse_images(image_files)\n",
    "\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pkl.dump(mp_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructure the data\n",
    "mp_data = list(map(lambda x: x.pose_landmarks[0][:LANDMARK_POINTS] if len(x.pose_landmarks) == 1 else None, mp_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.000000, max: 1.000000, mean: 0.874821, median: 1.000000\n",
      "cnt_blw_cutoff: 1454 (is 13.450509%)\n"
     ]
    }
   ],
   "source": [
    "movements = np.zeros((len(mp_data) - 1, LANDMARK_POINTS), dtype=np.float32)\n",
    "\n",
    "for i in range(1, len(mp_data) - 1):\n",
    "    if mp_data[i] is None or mp_data[i - 1] is None:\n",
    "        movements[i - 1] = np.nan\n",
    "    else:\n",
    "        for j in range(LANDMARK_POINTS):\n",
    "            p1 = mp_data[i - 1][j]\n",
    "            p2 = mp_data[i][j]\n",
    "\n",
    "            movements[i - 1][j] = calc_distance([p1.x, p1.y, p1.z], [p2.x, p2.y, p2.z])\n",
    "\n",
    "\n",
    "\n",
    "# for every movement, calculate the percentage of how many points moved less than the threshold\n",
    "movements_below_threshold = np.sum(movements < TRESHOLD, axis=1, dtype=np.float32) / np.float32(LANDMARK_POINTS)\n",
    "\n",
    "print(f\"min: {np.min(movements_below_threshold):.6f}, max: {np.max(movements_below_threshold):.6f}, mean: {np.mean(movements_below_threshold):.6f}, median: {np.median(movements_below_threshold):.6f}\")\n",
    "print(f\"cnt_blw_cutoff: {np.sum(movements_below_threshold < CUTOFF)} (is {100 * np.sum(movements_below_threshold < CUTOFF) / len(movements_below_threshold):.6f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moving_route(p1: np.array, p2: np.array, frames):\n",
    "    \"\"\"\n",
    "    Generates \"frames\" points between p1 and p2 to simulate a moving route.\n",
    "    p1 and p2 are 3D points.\n",
    "    \"\"\"\n",
    "\n",
    "    route = np.zeros((frames, LANDMARK_DIM))\n",
    "\n",
    "    for i in range(frames):\n",
    "        route[i] = p1 + (p2 - p1) * (i / frames)\n",
    "\n",
    "    return route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_frames = 3\n",
    "\n",
    "correct_frames = np.ones(len(movements_below_threshold), dtype=bool)\n",
    "last_correct_frames = recovery_frames\n",
    "\n",
    "# assuming that first minimal_continue_frames frames are correct\n",
    "\n",
    "for i in range(recovery_frames, len(movements_below_threshold)):\n",
    "    if movements_below_threshold[i] > CUTOFF:\n",
    "        last_correct_frames = np.max([last_correct_frames, last_correct_frames + 1])\n",
    "\n",
    "        if last_correct_frames >= recovery_frames:\n",
    "            correct_frames[i] = True\n",
    "        else:\n",
    "            correct_frames[i] = False\n",
    "    else:\n",
    "        correct_frames[i] = False\n",
    "        last_correct_frames = 0\n",
    "\n",
    "correct_frames[-1] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "for i in range(recovery_frames, len(correct_frames)):\n",
    "    if not correct_frames[i]:\n",
    "        j = i + 1\n",
    "        while True:\n",
    "            if correct_frames[j]:\n",
    "                break\n",
    "            j += 1\n",
    "\n",
    "        for k in range(i, j):\n",
    "            mp_data[k] = deepcopy(mp_data[i - 1])\n",
    "            correct_frames[k] = True\n",
    "\n",
    "        for point in range(LANDMARK_POINTS):\n",
    "\n",
    "            p1 = mp_data[i - 1][point]\n",
    "            p2 = mp_data[j][point]\n",
    "\n",
    "            route = get_moving_route(np.array([p1.x, p1.y, p1.z]), np.array([p2.x, p2.y, p2.z]), j - i)\n",
    "\n",
    "            for k in range(i, j):\n",
    "                mp_data[k][point].x = route[k - i][0]\n",
    "                mp_data[k][point].y = route[k - i][1]\n",
    "                mp_data[k][point].z = route[k - i][2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DrawingTask(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def draw(self, frame_index, image, landmarks):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrawMovementThreshold(DrawingTask):\n",
    "\n",
    "    def draw(self, frame_i, image, _):\n",
    "        if frame_i > 0:\n",
    "            val = movements_below_threshold[frame_i - 1]\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                f\"val: {val:.6f}\",\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "        \n",
    "        return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrawContours(DrawingTask):\n",
    "    def draw(self, _, image, landmarks):\n",
    "        if landmarks is None:\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                \"None\",\n",
    "                (image.shape[1] // 2, image.shape[0] // 2),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # draw circle in the middle of the face\n",
    "            \n",
    "            avg_x = np.mean([landmark.x for landmark in landmarks])\n",
    "            avg_y = np.mean([landmark.y for landmark in landmarks])\n",
    "\n",
    "            cv2.circle(\n",
    "                image,\n",
    "                (int(avg_x * image.shape[1]), int(avg_y * image.shape[0])),\n",
    "                5,\n",
    "                (0, 255, 0),\n",
    "                -1,\n",
    "            )\n",
    "\n",
    "            # below code may be used to draw all landmarks if all points are included\n",
    "\n",
    "            # landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "            # landmarks_proto.landmark.extend(\n",
    "            #     [landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in landmarks]\n",
    "            # )\n",
    "\n",
    "            # mp.solutions.drawing_utils.draw_landmarks(\n",
    "            #     image=image,\n",
    "            #     landmark_list=landmarks_proto,\n",
    "            #     connections=mp.solutions.pose.POSE_CONNECTIONS,\n",
    "            #     landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(\n",
    "            #         color=(255, 255, 255), thickness=2, circle_radius=2\n",
    "            #     ),\n",
    "            #     connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(\n",
    "            #         color=(49, 125, 237), thickness=2, circle_radius=2\n",
    "            #     ),\n",
    "            # )\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tasks = [\n",
    "    DrawMovementThreshold(),\n",
    "    DrawContours(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_skeletons = []\n",
    "\n",
    "for frame_i, (image, landmarks) in enumerate(zip(image_files, mp_data)):\n",
    "\n",
    "    image = cv2.imread(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for task in draw_tasks:\n",
    "        image = task.draw(frame_i, image, landmarks)\n",
    "\n",
    "    images_skeletons.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating video: /home/kappa/dev/computer-vision/proj/output.mp4\n",
      "Frame size: 600x600, Frame rate: 30 fps\n",
      "Video successfully saved to '/home/kappa/dev/computer-vision/proj/output.mp4'.\n"
     ]
    }
   ],
   "source": [
    "output_video_path = os.path.join(os.path.abspath(OUTPUT_PATH), VIDEO_FILE)\n",
    "\n",
    "# delete the video if it already exists\n",
    "if os.path.exists(output_video_path):\n",
    "    os.remove(output_video_path)\n",
    "\n",
    "width, height = RESOLUTION\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "video_writer = cv2.VideoWriter(output_video_path, fourcc, FRAME_RATE, (width, height))\n",
    "\n",
    "print(f\"Creating video: {output_video_path}\")\n",
    "print(f\"Frame size: {width}x{height}, Frame rate: {FRAME_RATE} fps\")\n",
    "\n",
    "for image in images_skeletons:\n",
    "    video_writer.write(image)\n",
    "\n",
    "video_writer.release()\n",
    "print(f\"Video successfully saved to '{output_video_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
